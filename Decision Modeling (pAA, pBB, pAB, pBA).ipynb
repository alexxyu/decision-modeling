{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import e\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "class DecisionModeler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def p_cc2a(self, dp, k1, k2):\n",
    "        a_given_a = st.norm.cdf(k1 + dp/2)\n",
    "        b_given_a = 1 - st.norm.cdf(k2 + dp/2)\n",
    "        a_given_b = st.norm.cdf(k1 - dp/2)\n",
    "        b_given_b = 1 - st.norm.cdf(k2 - dp/2)\n",
    "        \n",
    "        pAA = a_given_a*b_given_a + b_given_a*a_given_a\n",
    "        pBB = a_given_b*b_given_b + b_given_b*a_given_b\n",
    "        pAB = a_given_a*b_given_b + b_given_a*a_given_b\n",
    "        pBA = a_given_b*b_given_a + b_given_b*a_given_a\n",
    "\n",
    "        return pAA, pBB, pAB, pBA\n",
    "    \n",
    "    def p_df2(self, dp, k1, k2):\n",
    "        pAA = pBB = st.norm.cdf(-k1/math.sqrt(2)) + st.norm.cdf(-k2/math.sqrt(2))\n",
    "        pAB = st.norm.cdf((-dp - k2)/math.sqrt(2)) + st.norm.cdf((dp - k1)/math.sqrt(2))\n",
    "        pBA = st.norm.cdf((-dp - k1)/math.sqrt(2)) + st.norm.cdf((dp - k2)/math.sqrt(2))\n",
    "        \n",
    "        return pAA, pBB, pAB, pBA\n",
    "    \n",
    "    def p_lr2(self, dp, b1, b2):\n",
    "        if b1 > 1:\n",
    "            pAB = 1 - 2*(1 - st.norm.cdf(np.log(b1)/dp - dp/2))*(1 - st.norm.cdf(np.log(b1)/dp + dp/2))\n",
    "            p_false_b1 = 1 - ((1 - st.norm.cdf(np.log(b1)/dp - dp/2))**2 + (1 - st.norm.cdf(np.log(b1)/dp + dp/2))**2)\n",
    "        else:\n",
    "            pAB = ((1 - st.norm.cdf(np.log(1/b1)/dp - dp/2))**2 + (1 - st.norm.cdf(np.log(1/b1)/dp + dp/2))**2)\n",
    "            p_false_b1 = 2*(1 - st.norm.cdf(np.log(1/b1)/dp - dp/2))*(1 - st.norm.cdf(np.log(1/b1)/dp + dp/2))\n",
    "            \n",
    "        if b2 > 1:\n",
    "            pBA = 1 - 2*(1 - st.norm.cdf(np.log(b2)/dp - dp/2))*(1 - st.norm.cdf(np.log(b2)/dp + dp/2))\n",
    "            p_false_b2 = 1 - ((1 - st.norm.cdf(np.log(b2)/dp - dp/2))**2 + (1 - st.norm.cdf(np.log(b2)/dp + dp/2))**2)\n",
    "        else:\n",
    "            pBA = ((1 - st.norm.cdf(np.log(1/b2)/dp - dp/2))**2 + (1 - st.norm.cdf(np.log(1/b2)/dp + dp/2))**2)\n",
    "            p_false_b2 = 2*(1 - st.norm.cdf(np.log(1/b2)/dp - dp/2))*(1 - st.norm.cdf(np.log(1/b2)/dp + dp/2))\n",
    "            \n",
    "        pAA = pBB = (p_false_b1 + p_false_b2)/2\n",
    "        return pAA, pBB, pAB, pBA\n",
    "    \n",
    "    def generate_1_param_model(self, dp_vals, k_vals, p_function, filepath):\n",
    "        model = dict()\n",
    "        \n",
    "        # Variables used to keep track of progress\n",
    "        counter = progress = 0\n",
    "        total = len(dp_vals)\n",
    "        \n",
    "        # Calculate p-value tuples for each d' value\n",
    "        for dp in dp_vals:\n",
    "            dp_list = set()\n",
    "            for k in k_vals:\n",
    "                dp_list.add(p_function(dp, k, k))\n",
    "            model[dp] = list(dp_list)\n",
    "            \n",
    "            counter += 1\n",
    "            if counter/total >= progress+0.1:\n",
    "                progress += 0.1\n",
    "                print(f'{round(progress*100, 2)}% evaluated.')\n",
    "            \n",
    "        # Write data to json file\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(model, file)\n",
    "            print('Successfully written data to file.')\n",
    "\n",
    "    def generate_2_param_model(self, dp_vals, k_vals, p_function, filepath, model_type=\"\"):\n",
    "        model = dict()\n",
    "        model_type = model_type.lower()\n",
    "        \n",
    "        # Variables used to keep track of progress\n",
    "        counter = progress = 0\n",
    "        total = len(dp_vals)\n",
    "        \n",
    "        # Calculate p-value tuples for each d' value\n",
    "        for dp in dp_vals:\n",
    "            dp_list = set()\n",
    "            for k1 in k_vals:\n",
    "                for k2 in k_vals:\n",
    "                    # Ensure k2 value is appropriate depending on model\n",
    "                    if (model_type==\"cc2a\" or model_type==\"lr2\") and k2 < k1:\n",
    "                        continue\n",
    "                    if model_type==\"df2\" and k2 < -k1:\n",
    "                        continue\n",
    "                    # Calculate p-value tuple and add to current d' list\n",
    "                    dp_list.add(p_function(dp, k1, k2))\n",
    "            model[dp] = list(dp_list)\n",
    "            \n",
    "            counter += 1\n",
    "            if counter/total >= progress+0.1:\n",
    "                progress += 0.1\n",
    "                print(f'{round(progress*100, 2)}% evaluated.')\n",
    "            \n",
    "        # Write data to json file\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(model, file)\n",
    "            print('Successfully written data to file.')\n",
    "    \n",
    "    def get_distance(self, pHuman, pModel):\n",
    "        # 2d distance: (pAA_h + pBB_h - pAA_m - pBB_m)**2 + ...\n",
    "        dist_2d = math.sqrt((pHuman[0] + pHuman[1] - pModel[0] - pModel[1])**2 + (pHuman[2] + pHuman[3] - pModel[2] - pModel[3])**2)\n",
    "        return np.sqrt(np.sum((pHuman - pModel)**2)) + dist_2d\n",
    "    \n",
    "    def get_chi_squared(self, pHuman, pModel):\n",
    "        \n",
    "        # Number of trials in each block\n",
    "        n = 18\n",
    "        \n",
    "        # See Petrov equation 5\n",
    "        '''\n",
    "        chi_squared = 0\n",
    "        for pH, pM in zip(pHuman, pModel):\n",
    "            p_avg = (pH + pM) / 2\n",
    "            if p_avg == 0:\n",
    "                return np.inf\n",
    "            chi_squared += n*((pH-p_avg)**2 + (pM-p_avg)**2)/p_avg/(1-p_avg)\n",
    "        '''\n",
    "        \n",
    "        # See Collett equation 2.18\n",
    "        #chi_squared = sum([n*(pH-pM)**2/pM + n*((1-pH)-(1-pM))**2/(1-pM) for pH, pM in zip(pHuman, pModel)])\n",
    "        chi_squared = [n*(pH-pM)**2/pM for pH, pM in zip(pHuman, pModel)]\n",
    "        chi_squared.extend([n*((1-pH)-(1-pM))**2/(1-pM) for pH, pM in zip(pHuman, pModel)])\n",
    "                \n",
    "        return chi_squared\n",
    "    \n",
    "    def search_dp(self, pHuman_vals, model_input, output_prefix=\"sample\", default_df=None):\n",
    "        if default_df is None:\n",
    "            default_df = len(pHuman_vals)\n",
    "        \n",
    "        # Variables used to track best fit d' with distance, chi-squared, and closest points\n",
    "        min_dist = np.inf\n",
    "        min_chi_squared = None\n",
    "        best_dp = 0\n",
    "        best_pts = None\n",
    "        best_cs = None\n",
    "        \n",
    "        df = pd.DataFrame(columns=['dp', 'distance', 'chi-square', 'df', 'p-value'])\n",
    "        with open(model_input, 'rb') as file:\n",
    "            model = json.load(file)\n",
    "            \n",
    "            # Instantiate variables for individual d' values\n",
    "            dist_arr = np.empty(len(pHuman_vals))\n",
    "            chi_squared_arr = np.empty(len(pHuman_vals))\n",
    "            \n",
    "            # Variables used to keep track of progress\n",
    "            start = time.time()\n",
    "            counter = progress = 0\n",
    "            total = len(model.keys())\n",
    "            \n",
    "            # Try fit with each available d' value\n",
    "            for dp in model.keys():\n",
    "                # Reset variables for current d'\n",
    "                dist_arr.fill(np.inf)\n",
    "                chi_squared_arr.fill(np.inf)\n",
    "                best_dp_pts = np.empty((len(pHuman_vals), 4))\n",
    "                best_dp_cs = np.empty((len(pHuman_vals), 8))\n",
    "\n",
    "                for pModel in model[dp]:\n",
    "                    # Try p-value tuple fit with each human data point\n",
    "                    for index, pHuman in enumerate(pHuman_vals):\n",
    "                        dist = self.get_distance(pHuman, pModel)\n",
    "                        chi_squared = self.get_chi_squared(pHuman, pModel)\n",
    "                        \n",
    "                        # Check if minimal distance for current pModel, pHuman pair\n",
    "                        if dist < dist_arr[index]:\n",
    "                            dist_arr[index] = dist\n",
    "                            chi_squared_arr[index] = sum(chi_squared)\n",
    "                            \n",
    "                            best_dp_pts[index] = pModel\n",
    "                            best_dp_cs[index] = chi_squared\n",
    "                \n",
    "                # Update dataframe with data for current d'\n",
    "                curr_chi_square = sum([c for c in chi_squared_arr if c != np.inf])\n",
    "                curr_df = default_df - 2*np.count_nonzero(chi_squared_arr==np.inf)\n",
    "                df.loc[len(df)] = [dp, sum(dist_arr), curr_chi_square, curr_df, 1-st.chi2.cdf(curr_chi_square, curr_df)]\n",
    "                \n",
    "                # Update best fit variables if distance is new minimum\n",
    "                if sum(dist_arr) < min_dist:\n",
    "                    best_pts = best_dp_pts\n",
    "                    best_cs = best_dp_cs\n",
    "                    \n",
    "                    min_dist = sum(dist_arr)\n",
    "                    min_chi_squared = chi_squared_arr\n",
    "                    best_dp = float(dp)\n",
    "                    \n",
    "                counter += 1\n",
    "                if counter/total >= progress+0.1:\n",
    "                    progress += 0.1\n",
    "                    print(f'{round(progress*100, 2)}% evaluated.')\n",
    "        \n",
    "        # Write data to files\n",
    "        df = df.sort_values(by=['distance'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.to_csv(f'{output_prefix}_fit.csv')\n",
    "        \n",
    "        pts_df = pd.DataFrame(columns=['pAA', 'pBB', 'pAB', 'pBA'])\n",
    "        for p in best_pts:\n",
    "            pts_df.loc[len(pts_df)] = p\n",
    "        pts_df.to_csv(f'{output_prefix}_points.csv')\n",
    "        \n",
    "        cs = pd.DataFrame(columns=['AA','BB','AB','BA','AA_c','BB_c','AB_c','BA_c'])\n",
    "        for p in best_cs:\n",
    "            cs.loc[len(cs)] = p\n",
    "        cs.to_csv(f'{output_prefix}_cs.csv')\n",
    "        \n",
    "        print(f'Completed in {round((time.time()-start)/60, 2)} minutes.')\n",
    "        return best_dp, sum(chi_squared_arr), best_pts\n",
    "                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation\n",
    "Recommended criterion ranges: \n",
    "<ul>\n",
    "    <li>CC: [-3,3]</li>\n",
    "    <li>DF: [0,6]</li>\n",
    "    <li>LR: [e**-4,e**4]</li>\n",
    "    <li>RC: [0,2]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0% evaluated.\n",
      "20.0% evaluated.\n",
      "30.0% evaluated.\n",
      "40.0% evaluated.\n",
      "50.0% evaluated.\n",
      "60.0% evaluated.\n",
      "70.0% evaluated.\n",
      "80.0% evaluated.\n",
      "90.0% evaluated.\n",
      "Successfully written data to file.\n"
     ]
    }
   ],
   "source": [
    "modeler = DecisionModeler()\n",
    "\n",
    "dp_vals = np.linspace(0, 2.5, 11)\n",
    "#k_vals = np.linspace(-4, 4, 51)\n",
    "\n",
    "k_vals = np.logspace(-4, 4, 51, base=e)\n",
    "index = np.argwhere(dp_vals==0)\n",
    "dp_vals = np.delete(dp_vals, index)\n",
    "\n",
    "modeler.generate_2_param_model(dp_vals, k_vals, modeler.p_lr2, 'lr2_xs.json', model_type=\"lr2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0% evaluated.\n",
      "20.0% evaluated.\n",
      "30.0% evaluated.\n",
      "40.0% evaluated.\n",
      "50.0% evaluated.\n",
      "60.0% evaluated.\n",
      "70.0% evaluated.\n",
      "80.0% evaluated.\n",
      "90.0% evaluated.\n",
      "100.0% evaluated.\n",
      "Successfully written data to file.\n"
     ]
    }
   ],
   "source": [
    "modeler = DecisionModeler()\n",
    "\n",
    "dp_vals = np.linspace(0, 2.5, 11)\n",
    "k_vals = np.linspace(0, 6, 51)\n",
    "\n",
    "modeler.generate_2_param_model(dp_vals, k_vals, modeler.p_df2, 'df2_xs.json', model_type=\"df2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modeler = DecisionModeler()\n",
    "\n",
    "types = ['AA', 'BB', 'AB', 'BA']\n",
    "p_data = pd.read_csv('p_data.csv', index_col=\"Subject\")\n",
    "ratings_threshold = 1.0\n",
    "\n",
    "files = glob.glob('raw/8/*.mat')\n",
    "for f in files:\n",
    "    \n",
    "    dat = loadmat(f)\n",
    "    subject = f[max(f.rfind('/'), f.rfind('\\\\'))+1:f.find('.')]\n",
    "    \n",
    "    print(f'Currently checking subject {subject}.')\n",
    "    \n",
    "    num_ratings = 0\n",
    "    for i in range(1, 6):\n",
    "        if p_data.loc[subject][f'PF{i}'] <= ratings_threshold:\n",
    "            num_ratings += 1\n",
    "    \n",
    "    print(f'Number of ratings to be used: {num_ratings}')\n",
    "    \n",
    "    points = []\n",
    "    for t in types:\n",
    "        points.append(np.concatenate([dat[f'p_{t}_{n+1}Diff'][0] for n in range(num_ratings)]))\n",
    "    points = np.array(points).T\n",
    "    \n",
    "    best_dp, _, model_pts = modeler.search_dp(points, model_input='lr2_xs.json', output_prefix=f'models/lr2/{subject}', default_df=2*len(points))\n",
    "    clear_output()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('models/df2/*fit.csv')\n",
    "model = 'DF2'\n",
    "\n",
    "explainable = pd.read_csv('subject_models.csv', index_col='Subject')\n",
    "df = pd.DataFrame(columns=['subject', 'dp', 'distance', 'chi-square', 'df', 'p-value', 'dp2', 'distance2', 'chi-square2', 'df2', 'p-value2', 'explainable'])\n",
    "for f in files:\n",
    "    subject = f[max(f.rfind('/'), f.rfind('\\\\'))+1:f.find('_')]\n",
    "    \n",
    "    curr = pd.read_csv(f, index_col=0)\n",
    "    data = [subject, *curr.iloc[0].tolist(), *curr.iloc[1].tolist(), explainable.loc[subject][model]]\n",
    "    df.loc[len(df)] = data\n",
    "    \n",
    "df = df.sort_values(by=['p-value', 'chi-square'], ascending=[True, False])\n",
    "df['rejected'] = df['p-value']<0.05\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.to_csv('df2_8deg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
