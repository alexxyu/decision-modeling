{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "class DecisionModeler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def p_cc2a(self, dp, k1, k2):\n",
    "        a_given_a = st.norm.cdf(k1 + dp/2)\n",
    "        b_given_a = 1 - st.norm.cdf(k2 + dp/2)\n",
    "        a_given_b = st.norm.cdf(k1 - dp/2)\n",
    "        b_given_b = 1 - st.norm.cdf(k2 - dp/2)\n",
    "        \n",
    "        pAA = a_given_a*b_given_a + b_given_a*a_given_a\n",
    "        pBB = a_given_b*b_given_b + b_given_b*a_given_b\n",
    "        pAB = a_given_a*b_given_b + b_given_a*a_given_b\n",
    "        pBA = a_given_b*b_given_a + b_given_b*a_given_a\n",
    "\n",
    "        return pAA, pBB, pAB, pBA\n",
    "    \n",
    "    def generate_2_param_model(self, dp_vals, k_vals, p_function, filepath):\n",
    "        model = dict()\n",
    "        \n",
    "        # Variables used to keep track of progress\n",
    "        counter = progress = 0\n",
    "        total = len(dp_vals)\n",
    "        \n",
    "        # Calculate p-value tuples for each d' value\n",
    "        for dp in dp_vals:\n",
    "            dp_list = []\n",
    "            for k1 in k_vals:\n",
    "                for k2 in [k for k in k_vals if k >= k1]:\n",
    "                    # Calculate p-value tuple and add to current d' list\n",
    "                    dp_list.append(p_function(dp, k1, k2))\n",
    "            model[dp] = dp_list\n",
    "            \n",
    "            counter += 1\n",
    "            if counter/total >= progress+0.1:\n",
    "                progress += 0.1\n",
    "                print(f'{round(progress*100, 2)}% evaluated.')\n",
    "            \n",
    "        # Write data to json file\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(model, file)\n",
    "            print('Successfully written data to file.')\n",
    "    \n",
    "    def get_distance(self, pHuman, pModel):\n",
    "        return sum([(pH-pM)**2 for pH, pM in zip(pHuman, pModel)])\n",
    "    \n",
    "    def get_chi_squared(self, pHuman, pModel):\n",
    "        \n",
    "        # Number of trials in each block\n",
    "        n = 18\n",
    "        \n",
    "        # See Petrov equation 5\n",
    "        '''\n",
    "        chi_squared = 0\n",
    "        for pH, pM in zip(pHuman, pModel):\n",
    "            p_avg = (pH + pM) / 2\n",
    "            if p_avg == 0:\n",
    "                return np.inf\n",
    "            chi_squared += n*((pH-p_avg)**2 + (pM-p_avg)**2)/p_avg/(1-p_avg)\n",
    "        '''\n",
    "        \n",
    "        # See Collett equation 2.18\n",
    "        chi_squared = sum([n*(pH-pM)**2/pM + n*((1-pH)-(1-pM))**2/(1-pM) for pH, pM in zip(pHuman, pModel)])\n",
    "        \n",
    "        return chi_squared\n",
    "    \n",
    "    def search_dp(self, pHuman_vals, model_input, output_prefix=\"sample\", default_df=None):\n",
    "        if default_df is None:\n",
    "            default_df = len(pHuman_vals)\n",
    "        \n",
    "        # Variables used to track best fit d' with distance, chi-squared, and closest points\n",
    "        min_dist = np.inf\n",
    "        min_chi_squared = None\n",
    "        best_dp = 0\n",
    "        best_pts = None\n",
    "        \n",
    "        df = pd.DataFrame(columns=['dp', 'distance', 'chi-square', 'df', 'p-value'])\n",
    "        with open(model_input, 'rb') as file:\n",
    "            model = json.load(file)\n",
    "            \n",
    "            # Instantiate variables for individual d' values\n",
    "            dist_arr = np.empty(len(pHuman_vals))\n",
    "            chi_squared_arr = np.empty(len(pHuman_vals))\n",
    "            \n",
    "            # Variables used to keep track of progress\n",
    "            now = time.time()\n",
    "            ev_count = 0\n",
    "            counter = progress = 0\n",
    "            total = len(model.keys())\n",
    "            \n",
    "            # Try fit with each available d' value\n",
    "            for dp in model.keys():\n",
    "                # Reset variables for current d'\n",
    "                dist_arr.fill(np.inf)\n",
    "                chi_squared_arr.fill(np.inf)\n",
    "                best_dp_pts = np.empty((len(pHuman_vals), 4))\n",
    "\n",
    "                for pModel in model[dp]:\n",
    "                    # Try p-value tuple fit with each human data point\n",
    "                    for index, pHuman in enumerate(pHuman_vals):\n",
    "                        dist = self.get_distance(pHuman, pModel)\n",
    "                        chi_squared = self.get_chi_squared(pHuman, pModel)\n",
    "                        \n",
    "                        # Minimize distance and chi-square for current pModel, pHuman pair\n",
    "                        if dist < dist_arr[index]:\n",
    "                            best_dp_pts[index] = pModel\n",
    "\n",
    "                        dist_arr[index] = min(dist_arr[index], dist)\n",
    "                        chi_squared_arr[index] = min(chi_squared_arr[index], chi_squared)\n",
    "                        ev_count += 1\n",
    "                \n",
    "                # Update dataframe with data for current d'\n",
    "                curr_chi_square = sum([c for c in chi_squared_arr if c != np.inf])\n",
    "                curr_df = default_df - np.count_nonzero(chi_squared_arr==np.inf)\n",
    "                df.loc[len(df)] = [dp, sum(dist_arr), curr_chi_square, curr_df, 1-st.chi2.cdf(curr_chi_square, curr_df)]\n",
    "                \n",
    "                if sum(dist_arr) < min_dist:\n",
    "                    # Update best fit variables if distance is new minimum\n",
    "                    best_pts = best_dp_pts\n",
    "                    min_dist = sum(dist_arr)\n",
    "                    min_chi_squared = chi_squared_arr\n",
    "                    best_dp = float(dp)\n",
    "                counter += 1\n",
    "                if counter/total >= progress+0.1:\n",
    "                    progress += 0.1\n",
    "                    print(f'{round(progress*100, 2)}% evaluated.')\n",
    "                \n",
    "        # Write data to files\n",
    "        df = df.sort_values(by=['distance'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.to_csv(f'{output_prefix}_fit.csv')\n",
    "        \n",
    "        pts_df = pd.DataFrame(columns=['pAA', 'pBB', 'pAB', 'pBA'])\n",
    "        for p in best_pts:\n",
    "            pts_df.loc[len(pts_df)] = p\n",
    "        pts_df.to_csv(f'{output_prefix}_points.csv')\n",
    "        \n",
    "        return best_dp, sum(chi_squared_arr)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently checking subject GJ.\n",
      "Number of ratings to be used: 4\n",
      "10.0% evaluated.\n",
      "20.0% evaluated.\n",
      "30.0% evaluated.\n",
      "40.0% evaluated.\n",
      "50.0% evaluated.\n"
     ]
    }
   ],
   "source": [
    "modeler = DecisionModeler()\n",
    "\n",
    "types = ['AA', 'BB', 'AB', 'BA']\n",
    "dp_vals = np.linspace(0, 2.5, 101)\n",
    "p_data = pd.read_csv('p_data.csv', index_col=\"Subject\")\n",
    "\n",
    "files = glob.glob('raw/8/*.mat')\n",
    "#files = ['raw/8/CW.mat']\n",
    "for f in files:\n",
    "    dat = loadmat(f)\n",
    "    subject = f[6:f.find('.')]\n",
    "    \n",
    "    print(f'Currently checking subject {subject}.')\n",
    "    \n",
    "    num_ratings = 0\n",
    "    for i in range(1, 6):\n",
    "        if p_data.loc[subject][f'PF{i}'] <= 0.5:\n",
    "            num_ratings += 1\n",
    "    \n",
    "    print(f'Number of ratings to be used: {num_ratings}')\n",
    "    \n",
    "    points = []\n",
    "    num_ratings = 3\n",
    "    for t in types:\n",
    "        points.append(np.concatenate([dat[f'p_{t}_{n+1}Diff'][0] for n in range(num_ratings)]))\n",
    "    points = np.array(points).T\n",
    "    \n",
    "    modeler.search_dp(points, model_input='cc2a_small.json', output_prefix=f'cc2a/{subject}', default_df=2)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0% evaluated.\n",
      "20.0% evaluated.\n",
      "30.0% evaluated.\n",
      "40.0% evaluated.\n",
      "50.0% evaluated.\n",
      "60.0% evaluated.\n",
      "70.0% evaluated.\n",
      "80.0% evaluated.\n",
      "90.0% evaluated.\n",
      "100.0% evaluated.\n",
      "Successfully written data to file.\n"
     ]
    }
   ],
   "source": [
    "modeler = DecisionModeler()\n",
    "\n",
    "dp_vals = np.linspace(0, 2.5, 11)\n",
    "k_vals = np.linspace(-3, 3, 101)\n",
    "modeler.generate_2_param_model(dp_vals, k_vals, modeler.p_cc2a, 'cc2a_xs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
